{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression\n",
      "RMSE Train: 0.4868591830859797\n",
      "RMSE Test: 0.4864281552926156\n",
      "MAE Test: 0.3547365349684503\n",
      "R² Score Train: 0.6249407096879583\n",
      "R² Score Test: 0.6252455412816513\n",
      "\n",
      "Evaluating Lasso\n",
      "RMSE Train: 0.5524667846449777\n",
      "RMSE Test: 0.5524247411230333\n",
      "MAE Test: 0.4185779381269038\n",
      "R² Score Train: 0.517046252320295\n",
      "R² Score Test: 0.5166567689399588\n",
      "\n",
      "Evaluating Ridge\n",
      "RMSE Train: 0.48687094385680607\n",
      "RMSE Test: 0.4864360994651569\n",
      "MAE Test: 0.35480045972454954\n",
      "R² Score Train: 0.6249225892959037\n",
      "R² Score Test: 0.625233300467221\n",
      "\n",
      "Evaluating Random Forest\n",
      "RMSE Train: 0.1270372124839316\n",
      "RMSE Test: 0.3176911065729725\n",
      "MAE Test: 0.20521414200624918\n",
      "R² Score Train: 0.9744638684596586\n",
      "R² Score Test: 0.8401474700932938\n",
      "\n",
      "Evaluating XGBoost\n",
      "RMSE Train: 0.3773706793381024\n",
      "RMSE Test: 0.37941819672842386\n",
      "MAE Test: 0.2713998219630214\n",
      "R² Score Train: 0.7746645593346664\n",
      "R² Score Test: 0.7719942967027253\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Cargar los datos procesados\n",
    "df = pd.read_csv('../data/processed/EDA_Final.csv')\n",
    "\n",
    "# 2. Codificar las variables categóricas 'city' y 'state' en 'city_n' y 'state_n'\n",
    "df['city_n'] = pd.factorize(df['city'])[0]\n",
    "df['state_n'] = pd.factorize(df['state'])[0]\n",
    "\n",
    "# 3. Dividir los datos en X (features) e y (target)\n",
    "X = df[['bed', 'bath', 'acre_lot', 'log_house_size', \n",
    "        'one_adult_no_kids_living_wage', 'one_adult_one_kid_living_wage', \n",
    "        'one_adult_two_kids_living_wage', 'one_adult_three_kids_living_wage', \n",
    "        'two_adults_one_working_no_kids_living_wage', \n",
    "        'two_adults_one_working_one_kid_living_wage', \n",
    "        'two_adults_one_working_two_kids_living_wage', \n",
    "        'two_adults_one_working_three_kids_living_wage', \n",
    "        'two_adults_both_working_no_kids_living_wage', \n",
    "        'two_adults_both_working_one_kid_living_wage', \n",
    "        'two_adults_both_working_two_kids_living_wage', \n",
    "        'crime_index', 'city_n', 'state_n']]\n",
    "\n",
    "y = df['log_price']\n",
    "\n",
    "# 4. Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear una función para entrenar y evaluar modelos\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"RMSE Train: {rmse_train}\")\n",
    "    print(f\"RMSE Test: {rmse_test}\")\n",
    "    print(f\"MAE Test: {mae_test}\")\n",
    "    print(f\"R² Score Train: {r2_train}\")\n",
    "    print(f\"R² Score Test: {r2_test}\")\n",
    "    return model\n",
    "\n",
    "# Modelos para probar\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"Ridge\": Ridge(alpha=0.1),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de Modelos de Regresión para Predicción de Precios de Viviendas\n",
    "\n",
    "En esta sección, se entrenan y evalúan varios modelos de regresión con el objetivo de predecir el precio de viviendas (en su forma logarítmica). A continuación se describen los pasos y los resultados obtenidos para cada modelo.\n",
    "\n",
    "1. **Definición de los Modelos**:\n",
    "   - Se entrenan cinco modelos de regresión:\n",
    "     - **Linear Regression**: Un modelo lineal simple.\n",
    "     - **Lasso**: Regresión lineal con regularización L1 para reducir la complejidad del modelo.\n",
    "     - **Ridge**: Regresión lineal con regularización L2.\n",
    "     - **Random Forest**: Modelo de ensamble basado en múltiples árboles de decisión.\n",
    "     - **XGBoost**: Modelo de ensamble que optimiza los errores residuales de manera iterativa.\n",
    "\n",
    "2. **Entrenamiento y Predicciones**:\n",
    "   - Se utilizan los datos de entrenamiento para ajustar cada modelo y se realizan predicciones sobre los conjuntos de entrenamiento y prueba.\n",
    "   - Se utilizan las siguientes características: `bed`, `bath`, `acre_lot`, `log_house_size`, varias variables relacionadas con salarios de subsistencia, `crime_index`, y las variables codificadas `city_n` y `state_n`.\n",
    "\n",
    "3. **Evaluación del Rendimiento**:\n",
    "   - Para cada modelo, se calculan las métricas de rendimiento:\n",
    "     - **RMSE (Root Mean Squared Error)**: Mide la magnitud del error de predicción.\n",
    "     - **MAE (Mean Absolute Error)**: Promedio de la diferencia absoluta entre los valores predichos y reales.\n",
    "     - **R² Score**: Indica la proporción de la varianza en el precio de la vivienda que el modelo puede explicar.\n",
    "\n",
    "### Resultados de los Modelos:\n",
    "\n",
    "#### 1. Linear Regression:\n",
    "   - **RMSE Train**: 0.4869\n",
    "   - **RMSE Test**: 0.4864\n",
    "   - **MAE Test**: 0.3547\n",
    "   - **R² Train**: 0.625\n",
    "   - **R² Test**: 0.625\n",
    "   - **Interpretación**: Este modelo presenta un error moderado y un R² de 0.625, lo que indica que explica alrededor del 62% de la variabilidad en los precios de las viviendas.\n",
    "\n",
    "#### 2. Lasso:\n",
    "   - **RMSE Train**: 0.5525\n",
    "   - **RMSE Test**: 0.5524\n",
    "   - **MAE Test**: 0.4186\n",
    "   - **R² Train**: 0.517\n",
    "   - **R² Test**: 0.517\n",
    "   - **Interpretación**: Lasso tiene un mayor error comparado con la regresión lineal, con un R² más bajo (0.517). La regularización L1 no mejora el desempeño para este caso.\n",
    "\n",
    "#### 3. Ridge:\n",
    "   - **RMSE Train**: 0.4869\n",
    "   - **RMSE Test**: 0.4864\n",
    "   - **MAE Test**: 0.3548\n",
    "   - **R² Train**: 0.625\n",
    "   - **R² Test**: 0.625\n",
    "   - **Interpretación**: Los resultados de Ridge son casi idénticos a los de la regresión lineal simple, lo que sugiere que la regularización L2 no aporta una mejora significativa.\n",
    "\n",
    "#### 4. Random Forest:\n",
    "   - **RMSE Train**: 0.1270\n",
    "   - **RMSE Test**: 0.3177\n",
    "   - **MAE Test**: 0.2052\n",
    "   - **R² Train**: 0.974\n",
    "   - **R² Test**: 0.840\n",
    "   - **Interpretación**: Random Forest tiene un excelente desempeño con un R² de 0.840 en el conjunto de prueba. El error es significativamente menor que en los modelos lineales, y el modelo explica una gran proporción de la variabilidad en los precios de las viviendas.\n",
    "\n",
    "#### 5. XGBoost:\n",
    "   - **RMSE Train**: 0.3774\n",
    "   - **RMSE Test**: 0.3794\n",
    "   - **MAE Test**: 0.2714\n",
    "   - **R² Train**: 0.775\n",
    "   - **R² Test**: 0.772\n",
    "   - **Interpretación**: XGBoost presenta un rendimiento algo inferior al de Random Forest, con un R² de 0.772 en el conjunto de prueba. Sin embargo, sigue siendo mucho mejor que los modelos lineales.\n",
    "\n",
    "### Conclusiones:\n",
    "- **Random Forest** es el modelo más eficaz, con el menor RMSE y un alto R² en el conjunto de prueba, lo que indica una buena capacidad de predicción.\n",
    "- **XGBoost** también obtiene resultados sólidos, aunque ligeramente inferiores a Random Forest.\n",
    "- Los modelos lineales, como **Linear Regression**, **Ridge** y **Lasso**, no capturan tanta variabilidad en los precios de las viviendas, lo que sugiere que las relaciones entre las variables no son completamente lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisión Final sobre el Modelo: XGBoost\n",
    "\n",
    "Durante la evaluación de los modelos, se observó que aunque **Random Forest** presentó un rendimiento superior en términos de **RMSE** y **R²**, también mostró ciertas desventajas significativas que afectan su aplicabilidad en el problema actual:\n",
    "\n",
    "1. **Inestabilidad**: El modelo de **Random Forest** mostró inestabilidad en sus predicciones, particularmente al cambiar algunos de los parámetros del conjunto de entrenamiento. Esto puede ser un indicativo de sobreajuste, ya que el modelo parece aprender demasiado bien los datos de entrenamiento, pero pierde generalización cuando se enfrenta a datos no vistos.\n",
    "\n",
    "2. **Sobrefit (sobreajuste)**: Con un **R² Train** de 0.974 y un **R² Test** de 0.840, se evidencia una brecha significativa entre el rendimiento en el conjunto de entrenamiento y el de prueba. Este tipo de discrepancia es indicativo de sobreajuste, donde el modelo memoriza las relaciones en el conjunto de entrenamiento sin generalizar correctamente a datos nuevos.\n",
    "\n",
    "3. **Tiempo de Modelado**: Random Forest requiere mucho tiempo de procesamiento para entrenar el modelo debido a la gran cantidad de árboles (100 en este caso), lo que hace que su ejecución sea considerablemente más lenta que otros métodos, especialmente cuando se manejan grandes cantidades de datos o se requiere hacer ajustes rápidos.\n",
    "\n",
    "Por estas razones, se ha optado por utilizar **XGBoost** como el modelo final para la predicción de precios de viviendas. Aunque su rendimiento es ligeramente inferior en términos de **RMSE** y **R²** comparado con Random Forest (RMSE Test: 0.3794, R² Test: 0.772), **XGBoost** es más **estable** y presenta una mejor generalización entre los conjuntos de entrenamiento y prueba. Además, su tiempo de modelado es considerablemente más rápido, lo que facilita la iteración y ajuste de hiperparámetros en el futuro.\n",
    "\n",
    "### Ventajas de XGBoost:\n",
    "- **Mejor estabilidad**: Menos propenso al sobreajuste.\n",
    "- **Menor tiempo de entrenamiento**: Lo que facilita la optimización del modelo.\n",
    "- **Rendimiento robusto**: Aunque el **R² Test** (0.772) es un poco más bajo que Random Forest, sigue siendo muy alto y confiable para la tarea de predicción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
